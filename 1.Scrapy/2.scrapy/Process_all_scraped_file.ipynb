{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process 0 files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 0file [00:00, ?file/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Processing_Time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t2/21wy42zs3vqf4r_24_d7j4nc0000gn/T/ipykernel_13440/1613415510.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/t2/21wy42zs3vqf4r_24_d7j4nc0000gn/T/ipykernel_13440/1613415510.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m                            index=False)\n\u001b[1;32m    155\u001b[0m             \u001b[0mfirst_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;31m# 创建处理日志Excel文件\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0mcreate_processing_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessing_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;31m# 计算总处理时间\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/t2/21wy42zs3vqf4r_24_d7j4nc0000gn/T/ipykernel_13440/1613415510.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(processed_files)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_processing_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;34m\"\"\"创建处理日志Excel文件\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mlog_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mlog_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Processing_Time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mlog_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   7185\u001b[0m             )\n\u001b[1;32m   7186\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7187\u001b[0m             \u001b[0;31m# len(by) == 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7189\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7191\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7192\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Processing_Time'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 定义文件夹路径\n",
    "folder_path = './NamedReports'\n",
    "# 定义输出文件路径\n",
    "output_file = './combined_results.csv'\n",
    "# 定义处理日志Excel文件路径\n",
    "log_file = './processing_log.xlsx'\n",
    "# 定义当前时间和用户\n",
    "CURRENT_TIME = \"2025-02-28 21:41:05\"\n",
    "CURRENT_USER = \"AdaJSY\"\n",
    "\n",
    "def extract_site_id(df):\n",
    "    site_id = df.iloc[1, 1]\n",
    "    return site_id\n",
    "\n",
    "def create_processing_log(processed_files):\n",
    "    \"\"\"创建处理日志Excel文件\"\"\"\n",
    "    log_df = pd.DataFrame(processed_files)\n",
    "    log_df = log_df.sort_values('Processing_Time', ascending=False)\n",
    "    log_df.to_excel(log_file, index=False)\n",
    "\n",
    "def is_valid_file(file_path):\n",
    "    \"\"\"检查文件是否为有效的Excel文件（非隐藏文件）\"\"\"\n",
    "    return (not file_path.name.startswith('.') and \n",
    "            file_path.suffix.lower() == '.xls')\n",
    "\n",
    "def process_single_file(file_path):\n",
    "    try:\n",
    "        # 读取 HTML 文件中的所有表格\n",
    "        data_to_extract_html = pd.read_html(file_path)\n",
    "        site_id = extract_site_id(data_to_extract_html[0])\n",
    "        \n",
    "        # 获取第5个表格\n",
    "        original_df = data_to_extract_html[5]\n",
    "        \n",
    "        # 获取列的多级索引值\n",
    "        level0_values = original_df.columns.get_level_values(0)\n",
    "        level1_values = original_df.columns.get_level_values(1)\n",
    "        level2_values = original_df.columns.get_level_values(2)\n",
    "        \n",
    "        # 创建新的DataFrame\n",
    "        new_data = [level0_values, level1_values, level2_values]\n",
    "        new_data.extend(original_df.values)\n",
    "        df = pd.DataFrame(new_data)\n",
    "        \n",
    "        # 检查第一列，找出以 \"All\" 开头且以 \"bound\" 结尾的行的行索引\n",
    "        all_bound_rows_indices = df[df.iloc[:, 0].str.startswith('All', na=False) & \n",
    "                                  df.iloc[:, 0].str.endswith('bound', na=False)].index\n",
    "        \n",
    "        # 提取bound_texts\n",
    "        bound_texts = df.iloc[all_bound_rows_indices, 0].values\n",
    "        \n",
    "        # 拆分表格\n",
    "        dfs = {}\n",
    "        for i in range(len(all_bound_rows_indices) - 1):\n",
    "            start_idx = all_bound_rows_indices[i]\n",
    "            end_idx = all_bound_rows_indices[i + 1]\n",
    "            df_section = df.iloc[start_idx:end_idx].reset_index(drop=True)\n",
    "            dfs[bound_texts[i]] = df_section\n",
    "        \n",
    "        # 处理最后一个部分\n",
    "        df_section_last = df.iloc[all_bound_rows_indices[-1]:].reset_index(drop=True)\n",
    "        dfs[bound_texts[-1]] = df_section_last\n",
    "        \n",
    "        # 提取时间行及其上一行\n",
    "        for name, table in dfs.items():\n",
    "            table.iloc[:, 0] = table.iloc[:, 0].fillna('')\n",
    "            time_rows = table[table.iloc[:, 0].str.match(r'^\\d{2}:\\d{2}:\\d{2}$')].index\n",
    "            \n",
    "            if min(time_rows) > 0:\n",
    "                prev_row = [min(time_rows) - 1]\n",
    "            else:\n",
    "                prev_row = []\n",
    "            \n",
    "            rows_to_keep = sorted(list(set(time_rows) | set(prev_row)))\n",
    "            updated_table = table.iloc[rows_to_keep].reset_index(drop=True)\n",
    "            updated_table.iloc[0, 0] = \"Time\"\n",
    "            dfs[name] = updated_table\n",
    "        \n",
    "        # 删除特定列\n",
    "        for name, table in dfs.items():\n",
    "            for col in table.columns:\n",
    "                if table[col].iloc[0] in [\"Workday\", \"7 Day\", \"Count\"]:\n",
    "                    table = table.drop(columns=[col])\n",
    "            dfs[name] = table\n",
    "        \n",
    "        # 转换为长格式\n",
    "        final_dfs = []\n",
    "        for name, table in dfs.items():\n",
    "            table.columns = table.iloc[0]\n",
    "            table = table.iloc[1:]\n",
    "            table = table.reset_index(drop=True)\n",
    "            \n",
    "            time_column = table.columns[0]\n",
    "            long_format_table = pd.melt(table,\n",
    "                                      id_vars=[time_column],\n",
    "                                      var_name='Date',\n",
    "                                      value_name='MeltedValue')\n",
    "            \n",
    "            # 添加标识列\n",
    "            long_format_table.insert(0, 'Bound_Category', name)\n",
    "            long_format_table.insert(0, 'Site_ID', site_id)\n",
    "            \n",
    "            final_dfs.append(long_format_table)\n",
    "        \n",
    "        # 合并该文件的所有数据\n",
    "        return pd.concat(final_dfs, ignore_index=True), True, \"Success\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return None, False, str(e)\n",
    "\n",
    "def main():\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    # 创建一个空的列表来存储所有文件的数据\n",
    "    processing_log = []\n",
    "    \n",
    "    # 获取文件夹中的所有有效.xls文件\n",
    "    xls_files = [f for f in Path(folder_path).glob('*.xls') if is_valid_file(f)]\n",
    "    total_files = len(xls_files)\n",
    "    \n",
    "    print(f\"Starting to process {total_files} files...\")\n",
    "    \n",
    "    # 首先创建CSV文件并写入头部\n",
    "    first_file = True\n",
    "    \n",
    "    # 使用tqdm创建进度条\n",
    "    for file_path in tqdm(xls_files, desc=\"Processing files\", unit=\"file\"):\n",
    "        processing_time = CURRENT_TIME\n",
    "        \n",
    "        result_df, success, message = process_single_file(str(file_path))\n",
    "        \n",
    "        # 记录处理信息\n",
    "        log_entry = {\n",
    "            'File_Name': file_path.name,\n",
    "            'Processing_Time': processing_time,\n",
    "            'Status': 'Success' if success else 'Failed',\n",
    "            'Message': message,\n",
    "            'File_Size_KB': round(file_path.stat().st_size / 1024, 2),\n",
    "            'Processed_By': CURRENT_USER\n",
    "        }\n",
    "        processing_log.append(log_entry)\n",
    "        \n",
    "        if success and result_df is not None:\n",
    "            # 将处理后的数据直接写入CSV文件\n",
    "            result_df.to_csv(output_file, \n",
    "                           mode='w' if first_file else 'a',\n",
    "                           header=first_file,\n",
    "                           index=False)\n",
    "            first_file = False\n",
    "    \n",
    "    # 创建处理日志Excel文件\n",
    "    create_processing_log(processing_log)\n",
    "    \n",
    "    # 计算总处理时间\n",
    "    end_time = datetime.now()\n",
    "    processing_duration = end_time - start_time\n",
    "    \n",
    "    # 打印处理统计信息\n",
    "    success_count = sum(1 for log in processing_log if log['Status'] == 'Success')\n",
    "    print(\"\\nProcessing Summary:\")\n",
    "    print(f\"Total files: {total_files}\")\n",
    "    print(f\"Successfully processed: {success_count}\")\n",
    "    print(f\"Failed: {total_files - success_count}\")\n",
    "    print(f\"Total processing time: {processing_duration}\")\n",
    "    print(f\"Average time per file: {processing_duration/total_files}\")\n",
    "    \n",
    "    # 显示文件大小信息\n",
    "    if os.path.exists(output_file):\n",
    "        file_size_mb = os.path.getsize(output_file) / (1024 * 1024)\n",
    "        print(f\"\\nOutput file size: {file_size_mb:.2f} MB\")\n",
    "        print(f\"Results have been saved to: {output_file}\")\n",
    "        print(\"\\nTo read this CSV file later, you can use:\")\n",
    "        print(\"df = pd.read_csv('combined_results.csv')\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 849 failed files to reprocess...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:   0%|          | 3/849 [00:00<00:33, 24.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000000899717_2023-06-01_2023-06-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000679922_2024-10-01_2024-10-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000679109_2023-09-01_2023-09-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001215524_2023-09-01_2023-09-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000679921_2023-03-01_2023-03-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:   1%|          | 9/849 [00:00<00:40, 20.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000001390418_2024-12-01_2024-12-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001215468_2023-12-01_2023-12-11.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000679006_2023-06-01_2023-06-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000679006_2024-04-01_2024-04-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001215498_2023-11-01_2023-11-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:   1%|▏         | 12/849 [00:00<00:39, 20.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000000631192_2023-10-01_2023-10-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000679922_2023-07-01_2023-07-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001359200_2023-11-01_2023-11-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000899305_2024-10-01_2024-10-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:   2%|▏         | 15/849 [00:00<00:40, 20.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000000893354_2024-07-01_2024-07-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000830209_2024-05-01_2024-05-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001215463_2023-01-01_2023-01-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001215474_2025-01-01_2025-01-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:   2%|▏         | 18/849 [00:00<00:46, 18.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000001359427_2023-04-01_2023-04-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:   3%|▎         | 22/849 [00:01<00:44, 18.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000001215524_2024-02-01_2024-02-27.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000899171_2023-08-01_2023-08-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001215463_2023-06-01_2023-06-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001359528_2023-10-01_2023-10-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:   3%|▎         | 26/849 [00:01<00:45, 18.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000000970107_2023-08-01_2023-08-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000002650163_2025-01-01_2025-01-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000893332_2023-11-01_2023-11-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001910187_2023-10-01_2023-10-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000899012_2023-12-01_2023-12-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:   3%|▎         | 29/849 [00:01<00:42, 19.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000001210795_2023-11-01_2023-11-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000899171_2024-07-01_2024-07-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000679006_2023-08-01_2023-08-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:   4%|▍         | 32/849 [00:01<00:38, 21.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000000679921_2024-02-01_2024-02-29.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001270312_2024-08-01_2024-08-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:   4%|▍         | 35/849 [00:01<00:38, 21.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000000519818_2024-01-01_2024-01-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000679921_2024-04-01_2024-04-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000510390_2023-02-23_2023-02-28.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:   4%|▍         | 38/849 [00:01<00:36, 22.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000001359200_2024-04-01_2024-04-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001219178_2024-04-01_2024-04-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001210458_2024-12-01_2024-12-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001750254_2024-04-01_2024-04-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000893332_2024-10-01_2024-10-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:   5%|▍         | 41/849 [00:02<00:39, 20.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000000679921_2023-10-01_2023-10-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000899012_2023-07-01_2023-07-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:   5%|▌         | 44/849 [00:02<00:36, 22.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000000899305_2023-08-01_2023-08-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000679109_2023-10-01_2023-10-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000679006_2023-10-01_2023-10-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001350298_2024-07-02_2024-07-25.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:   6%|▌         | 47/849 [00:02<00:36, 22.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000001215969_2024-06-01_2024-06-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:   6%|▌         | 50/849 [00:02<00:40, 19.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000001210516_2023-09-01_2023-09-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000899171_2025-01-01_2025-01-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001215468_2023-11-01_2023-11-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:   6%|▌         | 53/849 [00:02<00:39, 20.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000000519818_2023-11-01_2023-11-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000519816_2024-03-01_2024-03-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:   7%|▋         | 56/849 [00:02<00:39, 20.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000001219420_2024-01-01_2024-01-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000679921_2023-11-01_2023-11-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001270312_2024-03-01_2024-03-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001359200_2024-09-01_2024-09-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000679109_2023-12-01_2023-12-16.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:   7%|▋         | 59/849 [00:02<00:38, 20.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000001510412_2024-06-01_2024-06-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000893354_2024-11-01_2024-11-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:   7%|▋         | 62/849 [00:03<00:41, 18.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000001215546_2024-03-01_2024-03-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000970107_2023-02-01_2023-02-28.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000893058_2024-09-01_2024-09-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:   8%|▊         | 66/849 [00:03<00:44, 17.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000002650163_2023-12-01_2023-12-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000519816_2023-11-01_2023-11-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001215524_2024-11-01_2024-11-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000899105_2023-05-01_2023-05-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000519818_2024-04-01_2024-04-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:   8%|▊         | 69/849 [00:03<00:41, 18.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000001215474_2023-12-01_2023-12-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001210458_2023-12-01_2023-12-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:   8%|▊         | 71/849 [00:03<00:44, 17.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000001215524_2024-03-02_2024-03-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001215419_2024-03-01_2024-03-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:   9%|▊         | 73/849 [00:03<00:45, 16.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000001215969_2024-11-01_2024-11-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:   9%|▉         | 75/849 [00:03<00:48, 16.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000001215969_2024-04-01_2024-04-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001510412_2025-02-01_2025-02-19.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:   9%|▉         | 77/849 [00:04<00:48, 15.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000001750254_2024-03-01_2024-03-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001910187_2023-12-01_2023-12-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:   9%|▉         | 79/849 [00:04<00:46, 16.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000001359427_2024-12-01_2024-12-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001210795_2023-04-01_2023-04-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001210458_2024-10-01_2024-10-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:  10%|▉         | 81/849 [00:04<00:47, 16.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000001215474_2023-09-01_2023-09-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:  10%|▉         | 84/849 [00:04<00:42, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000000899012_2024-11-01_2024-11-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000893383_2023-02-01_2023-02-24.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001219804_2024-07-01_2024-07-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001215524_2024-12-01_2024-12-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:  10%|█         | 86/849 [00:04<00:41, 18.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000000899305_2023-07-01_2023-07-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:  10%|█         | 89/849 [00:04<00:35, 21.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000001530332_2023-11-01_2023-11-30.xls: 处理文件时发生错误: no text parsed from document (line 0)\n",
      "Error processing NamedReports/000001359427_2024-03-01_2024-03-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001390418_2024-03-01_2024-03-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001870067_2023-09-01_2023-09-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001359427_2024-01-01_2024-01-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:  11%|█         | 95/849 [00:04<00:33, 22.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000001510412_2024-08-01_2024-08-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000893332_2024-01-01_2024-01-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001219438_2024-01-01_2024-01-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001359200_2024-07-01_2024-07-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000899907_2025-02-01_2025-02-19.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000519818_2024-08-01_2024-08-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:  12%|█▏        | 101/849 [00:05<00:35, 21.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000001210516_2023-03-01_2023-03-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000830209_2024-02-01_2024-02-29.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001510412_2024-11-01_2024-11-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000899171_2024-09-01_2024-09-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000679109_2024-04-01_2024-04-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:  13%|█▎        | 107/849 [00:05<00:35, 21.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000001215498_2024-02-01_2024-02-29.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000899171_2023-10-01_2023-10-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000899012_2023-04-01_2023-04-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001215474_2024-05-01_2024-05-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001210458_2023-02-02_2023-02-28.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:  13%|█▎        | 113/849 [00:05<00:32, 22.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000001219912_2023-01-01_2023-01-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000510390_2024-06-01_2024-06-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000679109_2023-08-01_2023-08-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000899171_2024-06-01_2024-06-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001219804_2023-11-01_2023-11-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000679921_2024-09-01_2024-09-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:  14%|█▎        | 116/849 [00:05<00:33, 21.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000000519818_2024-06-01_2024-06-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000519215_2023-05-01_2023-05-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000631192_2023-12-01_2023-12-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001750254_2024-07-01_2024-07-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:  14%|█▍        | 122/849 [00:06<00:31, 23.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000000679006_2023-01-01_2023-01-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000679109_2024-08-01_2024-08-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001215508_2023-03-01_2023-03-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001219013_2024-12-11_2024-12-31.xls: 处理文件时发生错误: no text parsed from document (line 0)\n",
      "Error processing NamedReports/000000519215_2023-06-01_2023-06-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000519215_2023-02-23_2023-02-28.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001219420_2024-02-01_2024-02-29.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:  15%|█▌        | 129/849 [00:06<00:29, 24.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000000519215_2023-09-01_2023-09-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001219438_2023-01-01_2023-01-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001350241_2025-02-01_2025-02-19.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000002650163_2024-10-01_2024-10-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001219420_2024-08-01_2024-08-13.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:  16%|█▌        | 132/849 [00:06<00:32, 22.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000001215419_2023-07-01_2023-07-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000210334_2024-07-01_2024-07-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000899717_2023-01-01_2023-01-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000001215463_2023-04-01_2023-04-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000899171_2023-06-01_2023-06-30.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reprocessing failed files:  16%|█▋        | 138/849 [00:06<00:34, 20.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing NamedReports/000001219912_2024-10-01_2024-10-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000519215_2024-08-01_2024-08-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000679921_2024-08-01_2024-08-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n",
      "Error processing NamedReports/000000519816_2024-12-01_2024-12-31.xls: 处理文件时发生错误: Too many levels: Index has only 1 level, not 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 235\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mUpdated output file size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_size_mb\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m MB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 235\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 191\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    189\u001b[0m processing_time \u001b[38;5;241m=\u001b[39m CURRENT_TIME\n\u001b[0;32m--> 191\u001b[0m result_df, success, message \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_single_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# 记录处理信息\u001b[39;00m\n\u001b[1;32m    194\u001b[0m log_entry \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFile_Name\u001b[39m\u001b[38;5;124m'\u001b[39m: file_name,\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessing_Time\u001b[39m\u001b[38;5;124m'\u001b[39m: processing_time,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReprocess_Attempt\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    202\u001b[0m }\n",
      "Cell \u001b[0;32mIn[4], line 30\u001b[0m, in \u001b[0;36mprocess_single_file\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_single_file\u001b[39m(file_path):\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;66;03m# 读取 HTML 文件中的所有表格\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m         data_to_extract_html \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;66;03m# 检查是否有足够的表格\u001b[39;00m\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_to_extract_html) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m6\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/html.py:1240\u001b[0m, in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend, storage_options)\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m   1225\u001b[0m     [\n\u001b[1;32m   1226\u001b[0m         is_file_like(io),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1230\u001b[0m     ]\n\u001b[1;32m   1231\u001b[0m ):\n\u001b[1;32m   1232\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing literal html to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread_html\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1234\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. To read from a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1237\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1238\u001b[0m     )\n\u001b[0;32m-> 1240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/html.py:983\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    972\u001b[0m p \u001b[38;5;241m=\u001b[39m parser(\n\u001b[1;32m    973\u001b[0m     io,\n\u001b[1;32m    974\u001b[0m     compiled_match,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    979\u001b[0m     storage_options,\n\u001b[1;32m    980\u001b[0m )\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 983\u001b[0m     tables \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m caught:\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;66;03m# if `io` is an io-like object, check if it's seekable\u001b[39;00m\n\u001b[1;32m    986\u001b[0m     \u001b[38;5;66;03m# and try to rewind it before trying the next parser\u001b[39;00m\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(io, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseekable\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m io\u001b[38;5;241m.\u001b[39mseekable():\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/html.py:249\u001b[0m, in \u001b[0;36m_HtmlFrameParser.parse_tables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_tables\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    242\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;124;03m    Parse and return all tables from the DOM.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03m    list of parsed (header, body, footer) tuples from tables.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m     tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_tables(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrs)\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_thead_tbody_tfoot(table) \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/html.py:791\u001b[0m, in \u001b[0;36m_LxmlFrameParser._build_doc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m         r \u001b[38;5;241m=\u001b[39m parse(f\u001b[38;5;241m.\u001b[39mhandle, parser\u001b[38;5;241m=\u001b[39mparser)\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;66;03m# try to parse the input in the simplest way\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    793\u001b[0m     r \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mgetroot()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/lxml/html/__init__.py:937\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(filename_or_url, parser, base_url, **kw)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parser \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    936\u001b[0m     parser \u001b[38;5;241m=\u001b[39m html_parser\n\u001b[0;32m--> 937\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43metree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32msrc/lxml/etree.pyx:3542\u001b[0m, in \u001b[0;36mlxml.etree.parse\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/lxml/etree.pyx:2417\u001b[0m, in \u001b[0;36mlxml.etree._elementTreeFactory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/lxml/etree.pyx:2424\u001b[0m, in \u001b[0;36mlxml.etree._newElementTree\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/lxml/etree.pyx:378\u001b[0m, in \u001b[0;36mlxml.etree._Document.getroot\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/lxml/etree.pyx:1630\u001b[0m, in \u001b[0;36mlxml.etree._elementFactory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/lxml/classlookup.pxi:403\u001b[0m, in \u001b[0;36mlxml.etree._parser_class_lookup\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/lxml/classlookup.pxi:456\u001b[0m, in \u001b[0;36mlxml.etree._custom_class_lookup\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/lxml/html/__init__.py:733\u001b[0m, in \u001b[0;36mHtmlElementClassLookup.lookup\u001b[0;34m(self, node_type, document, namespace, name)\u001b[0m\n\u001b[1;32m    730\u001b[0m             classes[name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(cur\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, bases, {})\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_classes \u001b[38;5;241m=\u001b[39m classes\n\u001b[0;32m--> 733\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlookup\u001b[39m(\u001b[38;5;28mself\u001b[39m, node_type, document, namespace, name):\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124melement\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    735\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_classes\u001b[38;5;241m.\u001b[39mget(name\u001b[38;5;241m.\u001b[39mlower(), HtmlElement)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 定义常量\n",
    "CURRENT_TIME = \"2025-02-28 21:48:27\"\n",
    "CURRENT_USER = \"AdaJSY\"\n",
    "\n",
    "# 定义文件路径\n",
    "folder_path = './NamedReports'\n",
    "log_file = './processing_log.xlsx'\n",
    "output_file = './combined_results_failed.csv'\n",
    "failed_log_file = './failed_processing_log.xlsx'\n",
    "\n",
    "def get_failed_files():\n",
    "    \"\"\"从处理日志中获取失败的文件列表\"\"\"\n",
    "    if not os.path.exists(log_file):\n",
    "        print(\"处理日志文件不存在！\")\n",
    "        return []\n",
    "    \n",
    "    log_df = pd.read_excel(log_file)\n",
    "    failed_files = log_df[log_df['Status'] == 'Failed']['File_Name'].tolist()\n",
    "    return failed_files\n",
    "\n",
    "def process_single_file(file_path):\n",
    "    try:\n",
    "        # 读取 HTML 文件中的所有表格\n",
    "        data_to_extract_html = pd.read_html(file_path)\n",
    "        \n",
    "        # 检查是否有足够的表格\n",
    "        if len(data_to_extract_html) < 6:\n",
    "            return None, False, f\"文件包含的表格数量不足: {len(data_to_extract_html)}\"\n",
    "            \n",
    "        try:\n",
    "            site_id = extract_site_id(data_to_extract_html[0])\n",
    "        except Exception as e:\n",
    "            return None, False, f\"提取Site ID失败: {str(e)}\"\n",
    "            \n",
    "        try:\n",
    "            # 获取第5个表格\n",
    "            original_df = data_to_extract_html[5]\n",
    "        except Exception as e:\n",
    "            return None, False, f\"获取第5个表格失败: {str(e)}\"\n",
    "        \n",
    "        # 获取列的多级索引值\n",
    "        level0_values = original_df.columns.get_level_values(0)\n",
    "        level1_values = original_df.columns.get_level_values(1)\n",
    "        level2_values = original_df.columns.get_level_values(2)\n",
    "        \n",
    "        # 创建新的DataFrame\n",
    "        new_data = [level0_values, level1_values, level2_values]\n",
    "        new_data.extend(original_df.values)\n",
    "        df = pd.DataFrame(new_data)\n",
    "        \n",
    "        # 检查第一列，找出以 \"All\" 开头且以 \"bound\" 结尾的行的行索引\n",
    "        all_bound_rows_indices = df[df.iloc[:, 0].str.startswith('All', na=False) & \n",
    "                                  df.iloc[:, 0].str.endswith('bound', na=False)].index\n",
    "        \n",
    "        if len(all_bound_rows_indices) == 0:\n",
    "            return None, False, \"没有找到bound行\"\n",
    "            \n",
    "        # 提取bound_texts\n",
    "        bound_texts = df.iloc[all_bound_rows_indices, 0].values\n",
    "        \n",
    "        # 拆分表格\n",
    "        dfs = {}\n",
    "        for i in range(len(all_bound_rows_indices) - 1):\n",
    "            start_idx = all_bound_rows_indices[i]\n",
    "            end_idx = all_bound_rows_indices[i + 1]\n",
    "            df_section = df.iloc[start_idx:end_idx].reset_index(drop=True)\n",
    "            dfs[bound_texts[i]] = df_section\n",
    "        \n",
    "        # 处理最后一个部分\n",
    "        df_section_last = df.iloc[all_bound_rows_indices[-1]:].reset_index(drop=True)\n",
    "        dfs[bound_texts[-1]] = df_section_last\n",
    "        \n",
    "        # 提取时间行及其上一行\n",
    "        for name, table in dfs.items():\n",
    "            table.iloc[:, 0] = table.iloc[:, 0].fillna('')\n",
    "            time_rows = table[table.iloc[:, 0].str.match(r'^\\d{2}:\\d{2}:\\d{2}$')].index\n",
    "            \n",
    "            if len(time_rows) == 0:\n",
    "                return None, False, f\"在 {name} 中没有找到时间行\"\n",
    "                \n",
    "            if min(time_rows) > 0:\n",
    "                prev_row = [min(time_rows) - 1]\n",
    "            else:\n",
    "                prev_row = []\n",
    "            \n",
    "            rows_to_keep = sorted(list(set(time_rows) | set(prev_row)))\n",
    "            updated_table = table.iloc[rows_to_keep].reset_index(drop=True)\n",
    "            updated_table.iloc[0, 0] = \"Time\"\n",
    "            dfs[name] = updated_table\n",
    "        \n",
    "        # 删除特定列\n",
    "        for name, table in dfs.items():\n",
    "            columns_to_drop = []\n",
    "            for col in table.columns:\n",
    "                if table[col].iloc[0] in [\"Workday\", \"7 Day\", \"Count\"]:\n",
    "                    columns_to_drop.append(col)\n",
    "            if columns_to_drop:\n",
    "                table = table.drop(columns=columns_to_drop)\n",
    "            dfs[name] = table\n",
    "        \n",
    "        # 转换为长格式\n",
    "        final_dfs = []\n",
    "        for name, table in dfs.items():\n",
    "            try:\n",
    "                table.columns = table.iloc[0]\n",
    "                table = table.iloc[1:]\n",
    "                table = table.reset_index(drop=True)\n",
    "                \n",
    "                time_column = table.columns[0]\n",
    "                long_format_table = pd.melt(table,\n",
    "                                          id_vars=[time_column],\n",
    "                                          var_name='Date',\n",
    "                                          value_name='MeltedValue')\n",
    "                \n",
    "                # 添加标识列\n",
    "                long_format_table.insert(0, 'Bound_Category', name)\n",
    "                long_format_table.insert(0, 'Site_ID', site_id)\n",
    "                \n",
    "                final_dfs.append(long_format_table)\n",
    "            except Exception as e:\n",
    "                return None, False, f\"处理表格 {name} 时发生错误: {str(e)}\"\n",
    "        \n",
    "        if not final_dfs:\n",
    "            return None, False, \"没有成功处理的表格\"\n",
    "            \n",
    "        # 合并该文件的所有数据\n",
    "        return pd.concat(final_dfs, ignore_index=True), True, \"Success\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        detailed_error = f\"处理文件时发生错误: {str(e)}\"\n",
    "        print(f\"Error processing {file_path}: {detailed_error}\")\n",
    "        return None, False, detailed_error\n",
    "\n",
    "def extract_site_id(df):\n",
    "    \"\"\"提取Site ID，增加错误处理\"\"\"\n",
    "    try:\n",
    "        # 尝试多种可能的位置\n",
    "        possible_positions = [(1, 1), (1, 0), (0, 1)]\n",
    "        for row, col in possible_positions:\n",
    "            try:\n",
    "                value = df.iloc[row, col]\n",
    "                if isinstance(value, str) and value.isdigit():\n",
    "                    return value\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # 如果上述方法都失败，尝试扫描整个DataFrame\n",
    "        for i in range(min(5, len(df))):\n",
    "            for j in range(min(5, len(df.columns))):\n",
    "                value = str(df.iloc[i, j])\n",
    "                if value.isdigit() and len(value) > 8:  # Site ID通常较长\n",
    "                    return value\n",
    "        \n",
    "        raise ValueError(\"无法找到有效的Site ID\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"提取Site ID时出错: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    # 获取失败的文件列表\n",
    "    failed_files = get_failed_files()\n",
    "    if not failed_files:\n",
    "        print(\"没有找到失败的文件记录\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(failed_files)} failed files to reprocess...\")\n",
    "    \n",
    "    # 创建新的处理日志\n",
    "    processing_log = []\n",
    "    \n",
    "    # 设置CSV文件的追加模式\n",
    "    append_mode = os.path.exists(output_file)\n",
    "    \n",
    "    # 处理失败的文件\n",
    "    for file_name in tqdm(failed_files, desc=\"Reprocessing failed files\"):\n",
    "        file_path = Path(folder_path) / file_name\n",
    "        \n",
    "        if not file_path.exists():\n",
    "            print(f\"文件不存在: {file_path}\")\n",
    "            continue\n",
    "            \n",
    "        processing_time = CURRENT_TIME\n",
    "        \n",
    "        result_df, success, message = process_single_file(str(file_path))\n",
    "        \n",
    "        # 记录处理信息\n",
    "        log_entry = {\n",
    "            'File_Name': file_name,\n",
    "            'Processing_Time': processing_time,\n",
    "            'Status': 'Success' if success else 'Failed',\n",
    "            'Message': message,\n",
    "            'File_Size_KB': round(file_path.stat().st_size / 1024, 2),\n",
    "            'Processed_By': CURRENT_USER,\n",
    "            'Reprocess_Attempt': True\n",
    "        }\n",
    "        processing_log.append(log_entry)\n",
    "        \n",
    "        if success and result_df is not None:\n",
    "            # 将处理后的数据追加到现有CSV文件\n",
    "            result_df.to_csv(output_file, \n",
    "                           mode='a',\n",
    "                           header=not append_mode,\n",
    "                           index=False)\n",
    "            append_mode = True\n",
    "    \n",
    "    # 保存新的处理日志\n",
    "    if processing_log:\n",
    "        pd.DataFrame(processing_log).to_excel(failed_log_file, index=False)\n",
    "    \n",
    "    # 计算处理时间\n",
    "    end_time = datetime.now()\n",
    "    processing_duration = end_time - start_time\n",
    "    \n",
    "    # 打印统计信息\n",
    "    success_count = sum(1 for log in processing_log if log['Status'] == 'Success')\n",
    "    print(\"\\nReprocessing Summary:\")\n",
    "    print(f\"Total failed files attempted: {len(failed_files)}\")\n",
    "    print(f\"Successfully reprocessed: {success_count}\")\n",
    "    print(f\"Failed again: {len(failed_files) - success_count}\")\n",
    "    print(f\"Total reprocessing time: {processing_duration}\")\n",
    "    \n",
    "    # 显示文件大小信息\n",
    "    if os.path.exists(output_file):\n",
    "        file_size_mb = os.path.getsize(output_file) / (1024 * 1024)\n",
    "        print(f\"\\nUpdated output file size: {file_size_mb:.2f} MB\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "表格数量: 8\n",
      "\n",
      "第5个表格的列结构:\n",
      "Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], dtype='int64')\n",
      "\n",
      "第5个表格的前几行:\n",
      "           0   1                              2   \\\n",
      "0  Event key: NaN                     QC Failure   \n",
      "1         NaN NaN  Weekends and defined holidays   \n",
      "\n",
      "                              3                              4   \\\n",
      "0                            NaN                     QC Outlier   \n",
      "1  Weekends and defined holidays  Weekends and defined holidays   \n",
      "\n",
      "                              5                              6   7   \\\n",
      "0                            NaN                    QC Atypical NaN   \n",
      "1  Weekends and defined holidays  Weekends and defined holidays NaN   \n",
      "\n",
      "                      8                      9                      10  11  \\\n",
      "0                 Events                    NaN                Special NaN   \n",
      "1  Holiday-affected days  Holiday-affected days  Holiday-affected days NaN   \n",
      "\n",
      "        12  13       14  \n",
      "0  Holiday NaN  Offline  \n",
      "1      NaN NaN      NaN  \n"
     ]
    }
   ],
   "source": [
    "# 在Jupyter中查看文件内容\n",
    "import pandas as pd\n",
    "\n",
    "# 选择一个失败的文件\n",
    "file_path = './NamedReports/000000899717_2023-06-01_2023-06-30.xls'\n",
    "\n",
    "# 读取文件中的所有表格\n",
    "tables = pd.read_html(file_path)\n",
    "\n",
    "# 看看第5个表格（索引为5）的结构\n",
    "print(\"表格数量:\", len(tables))\n",
    "print(\"\\n第5个表格的列结构:\")\n",
    "print(tables[5].columns)\n",
    "print(\"\\n第5个表格的前几行:\")\n",
    "print(tables[5].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0   1                              2   \\\n",
      "0  Event key: NaN                     QC Failure   \n",
      "1         NaN NaN  Weekends and defined holidays   \n",
      "\n",
      "                              3                              4   \\\n",
      "0                            NaN                     QC Outlier   \n",
      "1  Weekends and defined holidays  Weekends and defined holidays   \n",
      "\n",
      "                              5                              6   7   \\\n",
      "0                            NaN                    QC Atypical NaN   \n",
      "1  Weekends and defined holidays  Weekends and defined holidays NaN   \n",
      "\n",
      "                      8                      9                      10  11  \\\n",
      "0                 Events                    NaN                Special NaN   \n",
      "1  Holiday-affected days  Holiday-affected days  Holiday-affected days NaN   \n",
      "\n",
      "        12  13       14  \n",
      "0  Holiday NaN  Offline  \n",
      "1      NaN NaN      NaN  \n"
     ]
    }
   ],
   "source": [
    "print(tables[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
